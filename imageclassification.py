# -*- coding: utf-8 -*-
"""imageclassification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DMNwXlD1n_SdagmUo_rvyCPh_9ak8O7E
"""

# Commented out IPython magic to ensure Python compatibility.
import os 
import numpy as np
import tensorflow as tf
from tensorflow import keras 
import cv2 as c

# %matplotlib inline
import imghdr

!mkdir data

os.listdir('/content/data')
data_dir = '/content/data'

image_ext = ['png', 'jpg', 'jpeg']
# rmdir /content/drive/My Drive/DeepCID/model_cnn/.ipynb_checkpoints
!rmdir '/content/data/.ipynb_checkpoints'

from logging import exception
for image_class in os.listdir(data_dir):
  if image_class == '.ipynb_checkpoints':
    continue
  for image in os.listdir(os.path.join(data_dir, image_class)):
    image_path = os.path.join(data_dir,image_class, image)
    try:
      img= c.imread(image_path)
      tip = imghdr.what(image_path)
      if tip not in image_ext:
        print('worng extention {} '.format(image_path))
        os.remove(image_path)

    except Exception as e:
      print('issue with image {}'.format(image_path))
      
      
    
  print(image_class)

# for image_class in os.listdir(data_dir):
#   if image_class == '.ipynb_checkpoints':
#     continue
data = keras.utils.image_dataset_from_directory('/content/data')

data_itrator = data.as_numpy_iterator()

b = data_itrator.next()

# len(b)
b[1]

import matplotlib.pyplot as plt
fig, ax = plt.subplots(ncols=4, figsize=(20,20))
for idx, img in enumerate(b[0][:4]):
  ax[idx].imshow(img.astype(int))
  ax[idx].title.set_text(b[1][idx])

scaled = b[0]/255

scaled.max()

data = data.map(lambda x,y: (x/255, y))

s = data.as_numpy_iterator()
x = s.next()

fig, ax = plt.subplots(ncols=4, figsize=(20,20))
for idx, img in enumerate(x[0][:4]):
  ax[idx].imshow(img)
  ax[idx].title.set_text(x[1][idx])

len(data)



train_size = int(len(data)*.7)
val_size = int(len(data)*.2)+1
text_size = int(len(data)*.1)+1

print(train_size)
print(val_size)
print(text_size)

train = data.take(train_size) 
val = data.skip(train_size).take(val_size)
test = data.skip(train_size+val_size).take(text_size)

print(len(train))
print(len(val))
print(len(test))

from tensorflow import keras
from keras.models import Sequential
from keras.layers import Dense, Flatten, MaxPooling2D, Dropout, Conv2D

model = Sequential(
    [
        Conv2D(16,(3,3), 1,activation='relu', input_shape=(256,256,3)),
        MaxPooling2D(),
        Conv2D(32,(3,3), activation='relu'),
        MaxPooling2D(),
        Conv2D(16,(3,3),1, activation='relu'),
        MaxPooling2D(),
        Flatten(),
        Dense(256, activation='relu'),
        Dense(1, activation='sigmoid')

    ]
)

model.compile(
    optimizer='adam',
    loss='binary_crossentropy',
    metrics=['accuracy']
)

model.fit(train, validation_data=val, epochs=30)

from keras.metrics import Precision, Recall, BinaryAccuracy

pre = Precision()
re = Recall()
ba = BinaryAccuracy()

for batch in val.as_numpy_iterator():
  x,y = batch
  ywhat = model.predict(x)
  pre.update_state(y, ywhat)
  re.update_state(y, ywhat)
  ba.update_state(y, ywhat)

pre.result().numpy()

# img = c.imshow('/content/data/women/image1.png')
import imageio as iio
img = iio.imread("/content/data/women/image1.png")
# plt.imshow(img)
resize = tf.image.resize(img,(256,256))

x = model.predict(np.expand_dims(resize/255,0))